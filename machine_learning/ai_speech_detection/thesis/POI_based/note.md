## Phoneme-Level POI-Based Speech Deepfake Detection：以音素為單位的說話人偽造辨識方法

### **1. 方法架構**

本篇論文提出了一種基於「特定說話人（POI, Person of Interest）」的深偽語音辨識方法，**著重於音素層級**（phoneme-level）的分析，而非傳統的整段語音訊號處理。該方法核心理念是：**合成語音系統再怎麼精細，仍難以完美模擬說話人在「每一個音素單位」的發音特徵**，因此只要能細緻比對語音中的音素與某說話人的真實語料，就有機會辨識出是否為偽造。

方法上，作者建立一個說話人的語音特徵資料庫，將其語音分割為音素，再為每個音素抽取代表該發音方式的向量特徵。待辨識語音也經過相同處理，最後比對這些音素向量是否符合該 POI 的語音特性。這種方法具有可解釋性強、對語音細節敏感等優點，尤其對抗多樣化的深偽攻擊更具潛力。

---

### **2. 特徵設計（Feature Engineering）**

與以往單一向量表示整段語音不同，本研究對語音進行細緻處理。**每段語音經由音素分割器分解為音素，並針對每個音素抽取其特徵向量（d 維）**，這些向量保留了說話人在特定發音單位的獨特性。接著將所有音素特徵匯整為該說話人的「音素特徵資料庫」。

這些特徵包括音素間的變異與發音分佈，能有效捕捉深偽語音中難以模擬的細節。例如語音合成模型常忽略微妙的鼻音、摩擦音表現，而這些音素正是人類發音的關鍵區別指標。

---

### **3. 實驗與結果**

本研究在 VoxCeleb2 語音資料庫上進行實驗，資料中包含真實語音與多種深偽語音模型（如 Vall-E、YourTTS、Tortoise）生成的樣本。與其他 baseline 模型相比，本研究所提出的音素層級方法在辨識準確率（EER）與穩健性方面皆有明顯優勢。

在無額外壓縮的 clean 測試條件下，模型可達平均 EER = 7.3%，而在強壓縮或有雜訊的情境下仍保有良好表現。更重要的是，該方法能指出哪個音素出現偽造痕跡，提供解釋性結果。

---

### **4. 優點與貢獻**

**此方法不需使用深偽語音作為訓練資料，而是只使用 POI 的真實語音進行一類學習（One-Class Learning）**。因此在面對未知模型產生的語音時，也能保持穩定的泛化能力。此外，音素層級的處理方式讓模型能更準確地指出異常出現的部位，提升了多媒體鑑識中的可信度與可用性。

另一個亮點是可解釋性：**不同於黑盒的神經網路模型，研究者可明確指出是哪個音素與特徵向量偏離了真實發音行為**，使其成為一個透明且具鑑識力的工具。

---

### **5. 總結**

本研究提出了一種創新的「音素為單位」的說話人保護策略，在 POI-based 語音深偽檢測上具有明顯優勢。此方法跳脫傳統深偽檢測依賴大量合成樣本的框架，只需使用說話人的真實語音即可建立辨識模型，提升了資料取得與訓練的實用性。

[Phoneme-Level Analysis for Person-of-Interest Speech Deepfake Detection](./Phoneme-Level Analysis Deepfake Detection.pdf)

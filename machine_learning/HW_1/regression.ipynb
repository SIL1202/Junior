{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":125114,"databundleVersionId":14739055,"sourceType":"competition"},{"sourceId":14404428,"sourceType":"datasetVersion","datasetId":9199770}],"dockerImageVersionId":31234,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import KFold\n\n# 1. 安裝 pysr 庫\n# !pip install -q pysr\n\n# 2. 導入並執行 julia 安裝 (這步在 Kaggle 需要一點時間，大約 2-3 分鐘)\n# import pysr\n# pysr.install()\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Device:\", device)\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\nDATA_DIR = \"/kaggle/input/function-approximation-using-multilayer-perceptron\"\ntrain_path = os.path.join(DATA_DIR, \"train.csv\")\ntest_path  = os.path.join(DATA_DIR, \"test.csv\")\nsample_path = os.path.join(DATA_DIR, \"sample_submission.csv\")\n\ntrain_df = pd.read_csv(train_path)\ntest_df  = pd.read_csv(test_path)\nsample_df = pd.read_csv(sample_path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-07T15:55:10.299339Z","iopub.execute_input":"2026-01-07T15:55:10.300469Z","iopub.status.idle":"2026-01-07T15:55:10.330053Z","shell.execute_reply.started":"2026-01-07T15:55:10.300420Z","shell.execute_reply":"2026-01-07T15:55:10.328945Z"}},"outputs":[{"name":"stdout","text":"Device: cpu\n/kaggle/input/function-approximation-using-multilayer-perceptron/sample_submission.csv\n/kaggle/input/function-approximation-using-multilayer-perceptron/train.csv\n/kaggle/input/function-approximation-using-multilayer-perceptron/test.csv\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"# --- 貼在 Cell 2 的開頭 ---\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.preprocessing import KBinsDiscretizer\n\n# A. 計算 KNN 特徵 (用來抓局部規律)\nknn_reg = KNeighborsRegressor(n_neighbors=15, weights='distance', n_jobs=-1)\n# 訓練集預測 (用 K-Fold 避免洩漏)\ntrain_df['knn_pred'] = np.nan\nkf_knn = KFold(n_splits=5, shuffle=True, random_state=42)\nfor tr_idx, va_idx in kf_knn.split(train_df):\n    knn_reg.fit(train_df.loc[tr_idx, ['x1', 'x2']], train_df.loc[tr_idx, 'y'])\n    train_df.loc[va_idx, 'knn_pred'] = knn_reg.predict(train_df.loc[va_idx, ['x1', 'x2']])\n# 測試集預測\nknn_reg.fit(train_df[['x1', 'x2']], train_df['y'])\ntest_df['knn_pred'] = knn_reg.predict(test_df[['x1', 'x2']])\n\n# B. 計算 Target Encoding (r_te)\ndiscretizer = KBinsDiscretizer(n_bins=200, encode='ordinal', strategy='quantile')\ntrain_df['r'] = np.sqrt(train_df['x1']**2 + train_df['x2']**2)\ntest_df['r'] = np.sqrt(test_df['x1']**2 + test_df['x2']**2)\ntrain_df['r_bin'] = discretizer.fit_transform(train_df[['r']]).astype(int)\ntest_df['r_bin'] = discretizer.transform(test_df[['r']]).astype(int)\n\n# 訓練集 r_te\ntrain_df['r_te'] = np.nan\nfor tr_idx, va_idx in kf_knn.split(train_df):\n    bin_means = train_df.loc[tr_idx].groupby('r_bin')['y'].mean()\n    train_df.loc[va_idx, 'r_te'] = train_df.loc[va_idx, 'r_bin'].map(bin_means)\n# 測試集 r_te\nfinal_bin_means = train_df.groupby('r_bin')['y'].mean()\ntest_df['r_te'] = test_df['r_bin'].map(final_bin_means)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-07T15:55:10.332227Z","iopub.execute_input":"2026-01-07T15:55:10.332596Z","iopub.status.idle":"2026-01-07T15:55:10.546773Z","shell.execute_reply.started":"2026-01-07T15:55:10.332558Z","shell.execute_reply":"2026-01-07T15:55:10.545820Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"def get_pysr_feature(df):\n    # 這是根據你的 Hall of Fame 第 12 行轉換出來的 Python 代碼\n    # 注意：在 PySR 中 x0 是 x1，x1 是 x2\n    x1 = df['x1']\n    x2 = df['x2']\n    \n    # 公式：square(cos((((0.014435811 - square(x0)) - square(x1)) * 3.0000703) - -0.7421232)) + 0.50067115\n    inner = ((0.014435811 - x1**2 - x2**2) * 3.0000703) + 0.7421232\n    feature = np.cos(inner)**2 + 0.50067115\n    \n    return feature","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-07T15:55:10.547942Z","iopub.execute_input":"2026-01-07T15:55:10.548318Z","iopub.status.idle":"2026-01-07T15:55:10.554740Z","shell.execute_reply.started":"2026-01-07T15:55:10.548290Z","shell.execute_reply":"2026-01-07T15:55:10.553397Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"def apply_all_features(df):\n    # 1. 基礎幾何\n    df['r'] = np.sqrt(df['x1']**2 + df['x2']**2)\n    df['angle'] = np.arctan2(df['x2'], df['x1'])\n    \n    # 2. 頻率擴張\n    df['wave_9_1'] = np.sin(df['r'] * 9.1)\n    df['wave_7_3'] = np.cos(df['r'] * 7.3)\n    \n    # 3. 妳的公式 (確保這個函式還在！)\n    df['sr_feature'] = get_pysr_feature(df)\n    \n    return df\n\n# --- 關鍵修正：執行它！ ---\ntrain_df = apply_all_features(train_df)\ntest_df = apply_all_features(test_df)\n\n# 最終特徵組合\nfeatures_final = ['sr_feature', 'knn_pred', 'r_te', 'wave_9_1', 'wave_7_3', 'angle']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-07T15:55:10.555912Z","iopub.execute_input":"2026-01-07T15:55:10.556335Z","iopub.status.idle":"2026-01-07T15:55:10.583430Z","shell.execute_reply.started":"2026-01-07T15:55:10.556289Z","shell.execute_reply":"2026-01-07T15:55:10.582189Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"class XYDataset(Dataset):\n    def __init__(self, X, y=None):\n        self.X = torch.tensor(X, dtype=torch.float32)\n        self.y = None if y is None else torch.tensor(y, dtype=torch.float32)\n\n    def __len__(self):\n        return len(self.X)\n\n    def __getitem__(self, idx):\n        if self.y is None:\n            return self.X[idx]\n        return self.X[idx], self.y[idx]\n\nX = train_df[features_final].values.astype(np.float32)\ny = train_df[[\"y\"]].values.astype(np.float32)\nX_test = test_df[features_final].values.astype(np.float32)\n\nX_tr, X_va, y_tr, y_va = train_test_split(\n    X, y, test_size=0.2, random_state=42, shuffle=True\n)\n\nscaler_x = StandardScaler()\nscaler_y = StandardScaler()\n\nX_tr = scaler_x.fit_transform(X_tr)\nX_va = scaler_x.transform(X_va)\nX_test_s = scaler_x.transform(X_test)\n\ny_tr = scaler_y.fit_transform(y_tr)\ny_va = scaler_y.transform(y_va)\n\ntrain_loader = DataLoader(XYDataset(X_tr, y_tr), batch_size=128, shuffle=True)\nval_loader   = DataLoader(XYDataset(X_va, y_va), batch_size=256, shuffle=False)\ntest_loader  = DataLoader(XYDataset(X_test_s, None), batch_size=256, shuffle=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-07T15:55:10.585786Z","iopub.execute_input":"2026-01-07T15:55:10.586172Z","iopub.status.idle":"2026-01-07T15:55:10.607624Z","shell.execute_reply.started":"2026-01-07T15:55:10.586143Z","shell.execute_reply":"2026-01-07T15:55:10.606623Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"class ResidualBlock(nn.Module):\n    def __init__(self, dim):\n        super().__init__()\n        self.block = nn.Sequential(\n            nn.Linear(dim, dim),\n            nn.BatchNorm1d(dim),\n            nn.SiLU(), \n        )\n    def forward(self, x):\n        return x + self.block(x)\n\nclass ResDeepMLP(nn.Module):\n    def __init__(self, in_dim=len(features_final), hidden_dim=128): \n        super().__init__()\n        self.input_layer = nn.Sequential(nn.Linear(in_dim, hidden_dim), nn.SiLU())\n        self.res1 = ResidualBlock(hidden_dim)\n        self.res2 = ResidualBlock(hidden_dim)\n        self.output_layer = nn.Sequential(\n            nn.Linear(hidden_dim, 32),\n            nn.SiLU(),\n            nn.Linear(32, 1)\n        )\n    def forward(self, x):\n        x = self.input_layer(x)\n        x = self.res1(x)\n        x = self.res2(x)\n        return self.output_layer(x)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-07T15:55:10.608880Z","iopub.execute_input":"2026-01-07T15:55:10.609186Z","iopub.status.idle":"2026-01-07T15:55:10.618332Z","shell.execute_reply.started":"2026-01-07T15:55:10.609158Z","shell.execute_reply":"2026-01-07T15:55:10.617147Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"n_splits = 5\nkf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\ntest_preds_all = []\n\n# 重新取得 X，確保維度是 6\nX = train_df[features_final].values.astype(np.float32)\ny = train_df[[\"y\"]].values.astype(np.float32)\n\nfor fold, (train_idx, val_idx) in enumerate(kf.split(X)):\n    print(f\"\\n===== Fold {fold + 1} / {n_splits} =====\")\n    \n    X_tr_f, X_va_f = X[train_idx], X[val_idx]\n    y_tr_f, y_va_f = y[train_idx], y[val_idx]\n    \n    sc_x, sc_y = StandardScaler(), StandardScaler()\n    X_tr_s = sc_x.fit_transform(X_tr_f)\n    X_va_s = sc_x.transform(X_va_f)\n    X_te_s = sc_x.transform(X_test) # X_test 也要同步更新喔\n    y_tr_s = sc_y.fit_transform(y_tr_f)\n    y_va_s = sc_y.transform(y_va_f)\n    \n    train_loader = DataLoader(XYDataset(X_tr_s, y_tr_s), batch_size=16, shuffle=True)\n    val_loader   = DataLoader(XYDataset(X_va_s, y_va_s), batch_size=256, shuffle=False)\n    \n    best_val_fold = float(\"inf\")\n    best_state_fold = None\n    wait = 0\n    PATIENCE = 100\n    EPOCHS = 500\n    \n    # 1. 稍微加寬模型，但減少殘差塊，增加計算速度\n    model = ResDeepMLP(in_dim=len(features_final), hidden_dim=256).to(device) \n    \n    # 2. 拉大初始學習率，讓前期衝更快\n    optimizer = torch.optim.AdamW(model.parameters(), lr=3e-3, weight_decay=1e-5)\n    \n    # 3. 調整 SGDR 頻率：T_0 縮短，彈跳更頻繁\n    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\n        optimizer, T_0=25, T_mult=1, eta_min=1e-8\n    )\n\n    # 4. 數據加載：把 batch_size 壓到 16\n    train_loader = DataLoader(XYDataset(X_tr_s, y_tr_s), batch_size=16, shuffle=True)\n    criterion = nn.MSELoss()\n\n    for epoch in range(1, EPOCHS + 1):\n        model.train()\n        for xb, yb in train_loader:\n            xb, yb = xb.to(device), yb.to(device)\n            optimizer.zero_grad()\n            loss = criterion(model(xb), yb)\n            loss.backward()\n            optimizer.step()\n\n        model.eval()\n        val_losses = []\n        with torch.no_grad():\n            for xb, yb in val_loader:\n                xb, yb = xb.to(device), yb.to(device)\n                val_losses.append(criterion(model(xb), yb).item())\n        \n        # --- 修正處：確保 va_loss 被正確定義 ---\n        va_loss = np.mean(val_losses)\n        \n        # 更新 Scheduler\n        scheduler.step()\n\n        # 週期重啟時峰值衰減\n        if epoch % 25 == 0:\n            scheduler.base_lrs = [base_lr * 0.8 for base_lr in scheduler.base_lrs]\n            for param_group in optimizer.param_groups:\n                param_group['lr'] = scheduler.base_lrs[0]\n\n        # 紀錄最好的狀態\n        if va_loss < best_val_fold - 1e-7:\n            best_val_fold = va_loss\n            best_state_fold = {k: v.detach().cpu().clone() for k, v in model.state_dict().items()}\n            wait = 0\n        else:\n            wait += 1\n            if wait >= PATIENCE:\n                print(f\"Fold {fold+1} Early Stopping at Epoch {epoch}, Best Val: {best_val_fold:.6f}\")\n                break\n    \n    model.load_state_dict(best_state_fold)\n    model.eval()\n    with torch.no_grad():\n        fold_preds = model(torch.tensor(X_te_s).to(device)).cpu().numpy()\n        test_preds_all.append(sc_y.inverse_transform(fold_preds))\n\nfinal_preds = np.mean(test_preds_all, axis=0).flatten()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-07T15:55:10.619650Z","iopub.execute_input":"2026-01-07T15:55:10.620189Z"}},"outputs":[{"name":"stdout","text":"\n===== Fold 1 / 5 =====\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"# 修改 Cell 75\nsub = sample_df.copy()\nsub[\"y\"] = final_preds # 使用平均後的結果\nsub.to_csv(\"submission2.csv\", index=False)\nprint(\"Saved K-Fold Ensemble result!\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nfrom mpl_toolkits.mplot3d import Axes3D\n\nfig = plt.figure(figsize=(10, 8))\nax = fig.add_subplot(111, projection='3d')\n\n# 畫出 x1, x2 與 y 的關係\nax.scatter(train_df['x1'], train_df['x2'], train_df['y'], c=train_df['y'], cmap='viridis', s=2)\n\nax.set_xlabel('x1')\nax.set_ylabel('x2')\nax.set_zlabel('y')\nax.set_title('3D Surface Approximation Visualization')\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 看看哪個特徵跟 y 最像\ncorrelations = train_df.drop(columns=['id']).corr()['y'].abs().sort_values(ascending=False)\nprint(correlations)","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# 1. 安裝 pysr 庫\n",
    "# !pip install -q pysr\n",
    "\n",
    "# 2. 導入並執行 julia 安裝 (這步在 Kaggle 需要一點時間，大約 2-3 分鐘)\n",
    "# import pysr\n",
    "# pysr.install()\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "DATA_DIR = \"/kaggle/input/function-approximation-using-multilayer-perceptron\"\n",
    "train_path = os.path.join(DATA_DIR, \"train.csv\")\n",
    "test_path  = os.path.join(DATA_DIR, \"test.csv\")\n",
    "sample_path = os.path.join(DATA_DIR, \"sample_submission.csv\")\n",
    "\n",
    "train_df = pd.read_csv(train_path)\n",
    "test_df  = pd.read_csv(test_path)\n",
    "sample_df = pd.read_csv(sample_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def get_pysr_feature(df):\n",
    "    # 這是根據你的 Hall of Fame 第 12 行轉換出來的 Python 代碼\n",
    "    # 注意：在 PySR 中 x0 是 x1，x1 是 x2\n",
    "    x1 = df['x1']\n",
    "    x2 = df['x2']\n",
    "    \n",
    "    # 公式：square(cos((((0.014435811 - square(x0)) - square(x1)) * 3.0000703) - -0.7421232)) + 0.50067115\n",
    "    inner = ((0.014435811 - x1**2 - x2**2) * 3.0000703) + 0.7421232\n",
    "    feature = np.cos(inner)**2 + 0.50067115\n",
    "    \n",
    "    return feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def apply_all_features(df):\n",
    "    # 1. 原有的 14 個多項式與三角函數特徵\n",
    "    df['x1_2'] = df['x1'] ** 2\n",
    "    df['x2_2'] = df['x2'] ** 2\n",
    "    df['x1x2'] = df['x1'] * df['x2']\n",
    "    df['sin_x1'], df['cos_x1'] = np.sin(df['x1']), np.cos(df['x1'])\n",
    "    df['sin_x2'], df['cos_x2'] = np.sin(df['x2']), np.cos(df['x2'])\n",
    "    df['dist'] = np.sqrt(df['x1']**2 + df['x2']**2)\n",
    "    df['abs_diff'] = np.abs(df['x1'] - df['x2'])\n",
    "    df['sin_x1x2'] = np.sin(df['x1'] * df['x2'])\n",
    "    df['x1_cos_x2'] = df['x1'] * np.cos(df['x2'])\n",
    "    df['x2_cos_x1'] = df['x2'] * np.cos(df['x1'])\n",
    "    df['x1_2_x2'] = (df['x1']**2) * df['x2']\n",
    "    df['x2_2_x1'] = (df['x2']**2) * df['x1']\n",
    "\n",
    "    # 2. 呼叫剛才定義的公式函數，產生第 17 個特徵\n",
    "    df['sr_feature'] = get_pysr_feature(df)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# 應用至資料集\n",
    "train_df = apply_all_features(train_df)\n",
    "\n",
    "test_df = apply_all_features(test_df)\n",
    "\n",
    "# 更新最終特徵清單，確保後續模型輸入維度為 17\n",
    "# 根據你的相關係數表，只保留這 7 個最強特徵\n",
    "features_final = ['sr_feature', 'dist', 'cos_x2', 'x2_2', 'cos_x1', 'x1_2', 'abs_diff']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class XYDataset(Dataset):\n",
    "    def __init__(self, X, y=None):\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "        self.y = None if y is None else torch.tensor(y, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.y is None:\n",
    "            return self.X[idx]\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "X = train_df[features_final].values.astype(np.float32)\n",
    "y = train_df[[\"y\"]].values.astype(np.float32)\n",
    "X_test = test_df[features_final].values.astype(np.float32)\n",
    "\n",
    "X_tr, X_va, y_tr, y_va = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, shuffle=True\n",
    ")\n",
    "\n",
    "scaler_x = StandardScaler()\n",
    "scaler_y = StandardScaler()\n",
    "\n",
    "X_tr = scaler_x.fit_transform(X_tr)\n",
    "X_va = scaler_x.transform(X_va)\n",
    "X_test_s = scaler_x.transform(X_test)\n",
    "\n",
    "y_tr = scaler_y.fit_transform(y_tr)\n",
    "y_va = scaler_y.transform(y_va)\n",
    "\n",
    "train_loader = DataLoader(XYDataset(X_tr, y_tr), batch_size=128, shuffle=True)\n",
    "val_loader   = DataLoader(XYDataset(X_va, y_va), batch_size=256, shuffle=False)\n",
    "test_loader  = DataLoader(XYDataset(X_test_s, None), batch_size=256, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.block = nn.Sequential(\n",
    "            nn.Linear(dim, dim),\n",
    "            nn.BatchNorm1d(dim),\n",
    "            nn.SiLU(), \n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return x + self.block(x)\n",
    "\n",
    "class ResDeepMLP(nn.Module):\n",
    "    def __init__(self, in_dim=7, hidden_dim=128): \n",
    "        super().__init__()\n",
    "        self.input_layer = nn.Sequential(nn.Linear(in_dim, hidden_dim), nn.SiLU())\n",
    "        self.res1 = ResidualBlock(hidden_dim)\n",
    "        self.res2 = ResidualBlock(hidden_dim)\n",
    "        self.output_layer = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, 32),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(32, 1)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.input_layer(x)\n",
    "        x = self.res1(x)\n",
    "        x = self.res2(x)\n",
    "        return self.output_layer(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "n_splits = 5\n",
    "kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "test_preds_all = []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(X)):\n",
    "    print(f\"\\n===== Fold {fold + 1} / {n_splits} =====\")\n",
    "    \n",
    "    X_tr_f, X_va_f = X[train_idx], X[val_idx]\n",
    "    y_tr_f, y_va_f = y[train_idx], y[val_idx]\n",
    "    \n",
    "    sc_x, sc_y = StandardScaler(), StandardScaler()\n",
    "    X_tr_s = sc_x.fit_transform(X_tr_f)\n",
    "    X_va_s = sc_x.transform(X_va_f)\n",
    "    X_te_s = sc_x.transform(X_test)\n",
    "    y_tr_s = sc_y.fit_transform(y_tr_f)\n",
    "    y_va_s = sc_y.transform(y_va_f)\n",
    "    \n",
    "    train_loader = DataLoader(XYDataset(X_tr_s, y_tr_s), batch_size=32, shuffle=True, pin_memory=True, num_workers=2)\n",
    "    val_loader   = DataLoader(XYDataset(X_va_s, y_va_s), batch_size=256, shuffle=False, pin_memory=True, num_workers=2)\n",
    "    \n",
    "    best_val_fold = float(\"inf\")\n",
    "    best_state_fold = None\n",
    "    wait = 0\n",
    "    PATIENCE = 100\n",
    "    EPOCHS = 500\n",
    "    \n",
    "    model = ResDeepMLP(in_dim=len(features_final), hidden_dim=256).to(device)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-5)\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
    "        optimizer, T_0=40, T_mult=2, eta_min=1e-7\n",
    "    )\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    for epoch in range(1, EPOCHS + 1):\n",
    "        model.train()\n",
    "        for xb, yb in train_loader:\n",
    "            xb, yb = xb.to(device), yb.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            loss = criterion(model(xb), yb)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        model.eval()\n",
    "        val_losses = []\n",
    "        with torch.no_grad():\n",
    "            for xb, yb in val_loader:\n",
    "                xb, yb = xb.to(device), yb.to(device)\n",
    "                val_losses.append(criterion(model(xb), yb).item())\n",
    "        \n",
    "        va_loss = np.mean(val_losses)\n",
    "        scheduler.step()\n",
    "\n",
    "        if va_loss < best_val_fold - 1e-6:\n",
    "            best_val_fold = va_loss\n",
    "            best_state_fold = {k: v.detach().cpu().clone() for k, v in model.state_dict().items()}\n",
    "            wait = 0\n",
    "        else:\n",
    "            wait += 1\n",
    "            if wait >= PATIENCE:\n",
    "                print(f\"Fold {fold+1} Early Stopping at Epoch {epoch}, Best Val: {best_val_fold:.6f}\")\n",
    "                break\n",
    "    \n",
    "    model.load_state_dict(best_state_fold)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        X_te_tensor = torch.tensor(X_te_s).to(device)\n",
    "        fold_preds = model(X_te_tensor).cpu().numpy()\n",
    "        fold_preds_orig = sc_y.inverse_transform(fold_preds)\n",
    "        test_preds_all.append(fold_preds_orig)\n",
    "\n",
    "final_preds = np.mean(test_preds_all, axis=0).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# 修改 Cell 75\n",
    "sub = sample_df.copy()\n",
    "sub[\"y\"] = final_preds # 使用平均後的結果\n",
    "sub.to_csv(\"submission.csv\", index=False)\n",
    "print(\"Saved K-Fold Ensemble result!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "fig = plt.figure(figsize=(10, 8))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# 畫出 x1, x2 與 y 的關係\n",
    "ax.scatter(train_df['x1'], train_df['x2'], train_df['y'], c=train_df['y'], cmap='viridis', s=2)\n",
    "\n",
    "ax.set_xlabel('x1')\n",
    "ax.set_ylabel('x2')\n",
    "ax.set_zlabel('y')\n",
    "ax.set_title('3D Surface Approximation Visualization')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# 看看哪個特徵跟 y 最像\n",
    "correlations = train_df.drop(columns=['id']).corr()['y'].abs().sort_values(ascending=False)\n",
    "print(correlations)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 14739055,
     "sourceId": 125114,
     "sourceType": "competition"
    },
    {
     "datasetId": 9199770,
     "sourceId": 14404428,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31234,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
